{
  "agent_id": "coder2",
  "task_id": "task_6",
  "files": [
    {
      "name": "setup.py",
      "purpose": "Package installation setup",
      "priority": "low"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.HC_2507.22671v1_Designing_for_Self_Regulation_in_Informal_Programm",
    "project_type": "agent",
    "description": "Enhanced AI project based on cs.HC_2507.22671v1_Designing-for-Self-Regulation-in-Informal-Programm with content analysis. Detected project type: agent (confidence score: 5 matches).",
    "key_algorithms": [
      "Narrative",
      "Regulated",
      "Online",
      "Story-Telling",
      "Initiate",
      "Coil",
      "Transforming",
      "Ential",
      "Innovate",
      "Last"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.HC_2507.22671v1_Designing-for-Self-Regulation-in-Informal-Programm.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nDesigning for Self-Regulation in Informal\nProgramming Learning: Insights from a\nStorytelling-Centric Approach\nSami Saeed Alghamdi\nOpen Lab\nNewcastle University\nNewcastle upon Tyne, UK\ns.s.a.alghamdi2@newcastle.ac.ukChristopher Bull\nOpen Lab\nNewcastle University\nNewcastle upon Tyne, UK\nchristopher.bull@newcastle.ac.ukAhmed Kharrufa\nOpen Lab\nNewcastle University\nNewcastle upon Tyne, UK\nahmed.kharrufa@newcastle.ac.uk\nAbstract \u2014Many people learn programming independently\nfrom online resources and often report struggles in achieving\ntheir personal learning goals. Learners frequently describe their\nexperiences as isolating and frustrating, challenged by abundant\nuncertainties, information overload, and distraction, compounded\nby limited guidance. At the same time, social media serves as\na personal space where many engage in diverse self-regulation\npractices, including help-seeking, using external memory aids\n(e.g., self-notes), self-reflection, emotion regulation, and self-\nmotivation. For instance, learners often mark achievements and\nset milestones through their posts.\nIn response, we developed a system consisting of a web plat-\nform and browser extensions to support self-regulation online.\nThe design aims to add learner-defined structure to otherwise\nunstructured experiences and bring meaning to curation and\nreflection activities by translating them into learning stories with\nAI-generated feedback. We position storytelling as an integrative\napproach to design that connects resource curation, reflective and\nsensemaking practice, and narrative practices learners already\nuse across social platforms.\nWe recruited 15 informal programming learners who are\nregular social media users to engage with the system in a\nself-paced manner; participation concluded upon submitting a\nlearning story and survey. We used three quantitative scales\nand a qualitative survey to examine users\u2019 characteristics and\nperceptions of the system\u2019s support for their self-regulation. User\nfeedback suggests the system\u2019s viability as a self-regulation aid.\nLearners particularly valued in-situ reflection, automated story\nfeedback, and video annotation, while other features received\nmixed views. We highlight perceived benefits, friction points,\nand design opportunities for future AI-augmented self-regulation\ntools.\nIndex Terms \u2014Self-Regulation, Informal Learning, Story-\ntelling, Social Media, Adult Learners, Tool Support\nI. I NTRODUCTION\nMany people interested in programming take a self-directed\napproach to learning, drawing on a wide range of infor-\nmal online resources ( e.g., [1]\u2013[4]). According to a 2024\nStack Overflow survey, programming learners engage morefrequently with open-ended, nonlinear materials such as fo-\nrums, tutorials, technical documentation, and social media\nplatforms (e.g., YouTube, Twitch, and X) than with textbooks\nor structured e-learning courses (i.e., MOOCs) [5]. However,\nthis inclination toward informal online learning is often ac-\ncompanied by limited support for synthesizing information\n(i.e., actively combining insights from multiple resources)\nor engaging in sustained reflection. As a result, much of\ntheir learning\u2014whether intentional or incidental\u2014tends to be\nfragmented and transient [2], [4], [6], [7].\nWhile such sporadic engagement can be productive in the\nshort term (e.g., solving a specific task-based problem), it often\nlacks mechanisms for deeper understanding and misses oppor-\ntunities to consolidate learning\u2014both of which are important\nfor constructive learning in programming [8], especially given\nits exploratory nature [1], [4]. To regain structure and persist\nin such learning, learners adapt social media to support self-\nregulation strategies such as publicly reflecting on progress,\nmaintaining motivation through shared achievements, validat-\ning their learning approach with peers, and regulating emotions\n[6], [9], [10].\nDespite the prevalence of these self-regulatory practices in\nsocial media spaces, there has been little focused inquiry into\nlearners\u2019 experiences in these settings (e.g. [2], [6], [11], [12]).\nMost research on programming learning and self-regulation\nfocuses on formal settings such as university classrooms and\nMOOCs, where learners benefit from structured curricula,\ninstructor guidance, and feedback (e.g., [13]\u2013[18]). In con-\ntrast, informal learners operate in loosely organized, socially\ndriven contexts that require dedicated support. Addressing this\nchallenge calls for moving beyond frameworks developed for\ninstructor-led education toward design approaches grounded\nin the lived practices of self-directed learners [9], [19]\u2013[21].\nHowever, recognizing these needs is not the same as re-\nsponding to them. While some prior work has examined\ninformal learning needs [2], [6] and explored learners\u2019 use of\nonline platforms [3], [4], [12], [22], [23], few studies havearXiv:2507.22671v1  [cs.HC]  30 Jul 2025\n\n--- Page 2 ---\ntranslated these insights into tool designs, and even fewer\nhave evaluated them with informal learners. Thus, it remains\nunclear how to create tools that support self-regulation while\nfitting seamlessly into learners\u2019 everyday online routines. To\naddress this gap, we explored storytelling as a promising\ndesign element for supporting self-regulation in programming\n(e.g., [24]\u2013[29]).\nTransforming learning experiences into narratives promotes\nexternalization and fosters reflection, which helps surface\nhidden obstacles and strengthen metacognitive awareness [6],\n[30]. Stories also serve as engaging and memorable formats\nfor sharing practical knowledge and experiences, which are\nprevalent in technical domains [31]. Prior research has shown\nthat learners use storytelling as a form of social currency\nwithin online communities [6], [32], enabling learners to\naccess peer networks, identify with others\u2019 experiences, and\nsustain motivation\u2014key elements of self-regulated learning\n[1], [33]. Thus, we position storytelling as an integrative\napproach to design that connects informal practices (resource\ncuration, reflective and sensemaking, and narrative practices\n[3], [6], [11], [34], [35]) that learners already employ during\nlearning explorations and across social platforms.\nTo explore this storytelling-centric approach in a working\nsystem, we implemented a system comprising a backend web\nplatform (Link removed for anonymity) and three browser\nextensions (Link removed for anonymity). The design supports\nlearners in organizing learning into Resources, Tags, and\nStories, enabling them to reflect on online materials, tag them\nto construct learning paths across multiple resources, and\ngenerate narrative summaries of their progress, complemented\nby AI-generated feedback on their informal learning activities.\nThis paper makes two contributions. First, we report the\ndesign rationale and implementation of storytelling-centric\ntools to support self-regulation in informal programming\nlearning, grounded in prior findings about learner needs and\npractices. Second, we present findings from a short-term study\nof informal learners\u2019 experience using the system, highlighting\nperceived benefits, areas of friction, and design opportunities\nfor future AI-augmented self-regulation tools.\nThis study investigates the following research questions:\n\u2022RQ1: How can storytelling be integrated into the de-\nsign of self-regulation support for informal programming\nlearners?\n\u2022RQ2: What are learners\u2019 initial perceptions of the useful-\nness and usability of storytelling-centric self-regulation\ntools?\n\u2022RQ3: What design considerations can be derived from\nlearners\u2019 feedback?\nThe remainder of the paper is structured as follows. We first\nreview related work on the design space of tools supporting\nself-regulation of learning. We then present the system\u2019s de-\nsign and its rationale, followed by our study methodology and\nkey findings. We conclude with a discussion of implications\nfor designing self-regulation tools.II. R ELATED WORKS\nWe position our work within tool-based approaches sup-\nporting self-regulation among informal programming learners.\nThis section reviews prior literature on informal programming\nlearning, outlines key dimensions of self-regulation, surveys\nexisting self-regulation tools, and explores the potential of\nstorytelling to support self-regulation in learning to program.\nA. Informal Programming Learning and Self-Regulation\nInformal programming learners benefit from self-regulation\nsupport [1], [36], [37]. They require assistance in pursuing\nself-learning independently outside formal and structured en-\nvironments. Such settings, including university courses and\nMOOCs, frequently report high dropout rates among program-\nming learners [38]\u2013[41]. Self-regulation refers to organizing\nand utilizing personal and environmental resources effectively\nto support learning goals. It can be fostered through cognitive\nskills, like applying learning strategies, and metacognitive\nskills, such as planning, monitoring, and evaluation. Moti-\nvation is also key for promoting self-regulation [1], [42]\u2013\n[44]. Given the broad range of components, it is essential to\nprioritize the self-regulatory needs of specific populations to\ndesign effective solutions that address their needs.\nTo understand the nature of informal learning, Gao et al.\n[3] proposed a model (COIL) that describes how informal\nlearners (i.e., developers learning new APIs) engage in cycles\nof content curation, organization, and integration to codebase,\noffering a lens to understand the informal learning experience.\nThe COIL model is based on studying how developers practice\nAPI learning, and such a model can be extended to cover how\naccompanied self-regulation is practiced during such learning\nfor other learners such as less experienced, casual or novices\nlearners [45].\nRelatedly, Lie et al. [34] frame such informal learning\nactivity as daily online sensemaking developers engage on web\nbrowsers. They introduce Crystalline, a tool that automatically\ngathers and structures information into tables as develop-\ners explore and navigate the web to alleviate the manual\ncuration burden and support decision-making during learn-\ning. For developers, such sensemaking processes can support\nself-regulation by reducing cognitive load. However, novice\nlearners may require additional support beyond sensemaking,\nsuch as externalizing thoughts and offloading intentions and\nfuture goals. [46]\u2013[48]. Notably, these offloading mechanisms\nare not facilitated by structuring information for sensemaking\nalone. Therefore, balancing learner agency with automation\nrepresents a critical design tension when the goal is to support\nthe direction of learning.\nIn terms of social need, Chelana et al. identified \u201ccon-\nversational programmers\u201d as informal programming learners\nwho do not aim to integrate into a codebase through their\nlearning [12], [49]. Instead, they focus on other purposes,\nsuch as enhancing communication with programming teams.\nAlghamdi et al. further synthesized prior literature on informal\nprogramming learning, surfacing peer support and self-efficacy\nas important factors to support this population [1]. These social\n\n--- Page 3 ---\nneeds are actively facilitated through social media platforms\n[6], [50]\u2013[53]. The aforementioned studies highlight the social\nand motivational aspects of programming learning, stressing\nthe importance of interventions that foster relatedness [54] to\nsupport learning regulation and maintain continuity.\nB. Tool Support for Self-Regulation of Learning\nSelf-regulated learning literature in formal programming\neducation is well-established and growing(e.g., [43], [55]\u2013\n[59]). It emphasizes the teacher\u2019s role in teaching strategies,\ndesigning pedagogical interventions, and creating assignments\nto improve course outcomes. Correspondingly, tools in this\narea are primarily designed for structured environments, such\nas extensions to learning management systems or MOOCs,\nassuming an instructor-led environment with prepared mate-\nrials and predefined learning goals. Further, many tools are\nneither tailored to programming nor designed for informal\nlearning; prior literature reviews list tools that essentially\nassume structured, formal education settings [18], [60]. As\nsuch, programming learners operating in informal settings lack\ndedicated support for self-regulation and often rely on non-\nspecialized tools, including social platforms, to manage their\nlearning [1], [61].\nHaving a clear learning goal is essential for informal learn-\ning regulation and progression [6], [36]. However, informal\nlearners, especially novices, often lack this clarity [2], [6],\noverwhelmed by abundant resources and uncertainty [1]. This\nrepresents a key early obstacle in learning to program in-\ndependently. Thus, Rimika et al. [11], [62] designed paper-\nbased mock-ups to investigate the needs of individuals in\ntechnical domains for self-monitoring their learning. The study\nexamined interactive visual self-monitoring tools for informal\nlearners and found that such tools can enhance learners\u2019 ability\nto reflect on past experiences and plan future goals, especially\nwhen they offer user control, such as filterable progress views.\nBeyond goal setting, informal learners must also navigate\nthe challenges of maintaining focus in distracting digital\nenvironments. Self-control in web browsing is an important\ntopic in online experience literature for general users. It aims\nto reduce negative online experiences, such as distractions,\ninformation overload, and compulsive use [63]. Various tools\nsuch as blocking websites, usage logs and screen timers aim to\nmanage browsing experience [63]\u2013[65]. However, these tools\nprimarily focus on behavioural control and underserve other\nself-regulation needs, such as metacognitive and motivational\nones, which are essential for learning, warranting future re-\nsearch for an integrative approach.\nSimilarly, commercially available tools such as Forest [66]\nand Habitica [67] aim to help users \u2018stay focused\u2019 and \u2018achieve\ngoals\u2019 through gamified experiences. However, their role in in-\nformal programming learning remains unclear. These tools do\nnot seamlessly integrate with informal learning practices that\ninvolve curation, sensemaking, and self-directed exploration\n[3], [34]. Self-regulation of learning involves processes that\npromote ongoing engagement with learning goals, utilizing\nreflective practices and social learning [6], [52], [68], [69].C. Storytelling and Programming\nThe potential of storytelling is recognized in computing and\nsoftware engineering education and practice (e.g., [25], [28]\u2013\n[31], [70]\u2013[72]), primarily to enhance instructional delivery\nor serve as a documentation strategy that improves code com-\nprehension. Digital storytelling was discussed as a promising\napproach for fostering participation and collaboration in multi-\ndisciplinary software teams [72]. Further, Wuilmart et al. [28],\nstate that stories can help developers make sense of complex\ncodebases by linking narratives to specific development tasks.\nNonetheless, developers frequently report difficulty initiating\nnarrative [28], underscoring the need for storytelling scaffolds.\nIn the same vein, Amber et al. explored developers\u2019 various\nneeds for sensemaking tools [73]. For instance, they designed\n\u201cSodalite\u201d [74] and \u201cAdamite\u201d [75], which address developers\u2019\nneed to author \u2018stories\u2019 about their code as a long-form\nof documentation and to engage with API documentation\nvia annotation. They note that such tools enable them to\novercome the issue of poor documentation, allowing self-\nnotes and explanations for their sensemaking or sharing with\nother developers. Furthermore, Kery et al. [30] focused on\nliterate programming tools, such as Jupyter notebooks. They\ndemonstrated that data scientists organize cells in notebooks,\nforming narratives that help them understand their coding task\nexplorations.\nWhile these efforts highlight storytelling\u2019s value in formal\neducation and developers\u2019 contexts (e.g., engaging teaching,\nbetter code documentation, API learnability, and sensemaking\nduring exploration), they lack focus on specific issues for\nnovices learning informal programming. Namely, challenges\nthat precede coding practice including high uncertainty, lack of\ngoal clarity, and lack of communication efficiency in seeking\ncommunity support [1], [2]. In response, Alghamdi et al. anal-\nysed learner-authored narratives across various programming\nchannels on social media platforms [6]; their findings show\nthat learners often narrate their experiences in public posts to\ndocument progress, process setbacks, and connect with peer\ncommunities, to self-regulate their learning.\nFurther, three levels of tool support are identified and\nproposed to scaffold storytelling [6], as follows: (1) inter-\naction with resources (i.e., curation in alignment with [3],\n[34]), (2) managing experiences (i.e., classification, subgoal\nlabeling or tagging, in alignment with [40], [76], [77]), and (3)\nexternalization of these experiences , utilising Generative AI\nabilities (Aligning with these proposals [6], [74]). Together,\nthese levels of support aim to assist learners in articulating\nand managing their learning experiences. As such, storytelling\nsurfaced as a promising component to facilitate self-regulation\nand was proposed as a design element grounded in the learn-\ners\u2019 existing experiences and needs [6]. Nevertheless, current\nliterature has not yet extended to demonstrate how to position\nstorytelling in a design for informal learners or investigated\nits practical utility for self-regulation.\n\n--- Page 4 ---\nD. Synthesis\nWhile the potential of storytelling within programming ed-\nucation and practice has been examined, its implementation as\na learner-authored and self-regulation support element remains\nlargely underexplored. Informal programming learners usually\nrely on curation [3], [34] and sensemaking of fragmented\nonline resources. Also, they depend on social media to self-\nregulate during informal activities [6], [10]. Key aspects of\nself-regulation for this group highlight the importance of social\nconnections and reflection on experiences [1], [36], which\nalign with principles of self-determination [54] and experi-\nential learning theory [78]. Storytelling has been identified\nas a promising method to fulfil both needs [6]. However,\ncurrent tools do not adequately address the specific self-\nregulation dimensions identified for informal programming\nlearners. Therefore, this area warrants further research and\ndesign to enhance independent, self-directed learning.\nIII. D ESIGN\nIn this section, we will illustrate a scenario of a novice\ninformal learner, drawing inspiration from previous literature\nand fieldwork that investigated aspects related to informal\nprogramming learning ( e.g., [1]\u2013[4], [6], [36], [45]). Then,\nwe outline the design requirements for tools to support self-\nregulation in such informal experiences, and present the re-\nsulting tool design that responds to these requirements.\nA. Motivating Example\nConsider Amy, a self-taught novice programmer eager to\n\u201cget serious\u201d about coding. Her initial enthusiasm soon gives\nway to uncertainty: Should she explore JavaScript frameworks\nlike React or Vue? Focus on Python and data science? Try\nbackend development with Java, or game development with\nRust?\nWithout clear goals, guidance from peers, or visible role\nmodels, Amy cycles through tutorials without direction. She\ntentatively chooses Python, only to encounter new deci-\nsions\u2014Should she use notebooks or local files? Build GUIs\nwith Tkinter or PyQt? Eventually, she turns to Vue.js, drawn\nby its HTML-like familiarity, but soon encounters friction with\ntooling such as NPM.\nThough Amy engages with a wide array of technologies,\nher learning remains fragmented. She relies on ChatGPT for\ncode generation but struggles to understand how and why\nthe solutions work. Motivated moments\u2014such as building a\ndesktop app\u2014fade when she cannot retrace her steps or make\nsense of past decisions. Throughout her journey, Amy lacks\ncontinuity, self-efficacy, and peer support. Most importantly,\nshe lacks a goal that personally resonates with her to maintain\nmomentum.\nHer experience illustrates common barriers faced by in-\nformal learners: cognitive overload, resource fragmentation,\nlimited feedback, and declining motivation. Without tools that\nscaffold decision-making, support resource organization, and\nrender learning goals visible and personally meaningful, manyspikes in motivation fade away easily, and exploration efforts\nare lost and cannot be built upon.\nB. Design Rationale\nThe previous scenario highlights several challenges in infor-\nmal programming learning: resuming learning after interrup-\ntions, making sense of fragmented progress, and lacking goal\nclarity. As discussed in related works, most existing solutions\ncan support specific self-regulation components (e.g., sum-\nmaries to reduce cognitive load or self-control to manage dis-\ntraction alone). However, they might impose rigid workflows\nor fail to support seamless transitions between exploration and\nreflection; in other words, they fail to integrate seamlessly\ninto the informal experience identified (e.g., learners curating,\norganizing, integrating into codebases, or narrating progress\non social media).\nIn response, we position storytelling as an integrative\napproach to design that connects resource curation, reflective\nand sensemaking practice, and narrative practices learners\nalready employ across social platforms. By scaffolding story-\ntelling, learners may reconnect with their exploratory learning\nover time, solidifying their progress toward clearer goals\nand holding the potential to address self-regulation needs for\ninformal learners.\nC. Requirements\nWe formulated the following design requirements, informed\nby the motivating scenario, design rationale and related liter-\nature:\n\u2022R1. In-situ reflection during curation that allows learn-\ners to reflect across diverse resources and intentions\nduring the act of curation, supporting later sensemaking.\n\u2022R2. Resource organization to help learners transform\nfragmented content into coherent learning paths, so that\npast efforts can be built upon.\n\u2022R3. Turning curated learning paths into stories to\nsupport post-reflection and to enable the following:\n1)R3.1. Social mechanisms for community engage-\nment via sharing and exporting to social platforms.\n2)R3.2. AI-generated feedback based on learners\u2019\nstories, derived from curation and reflections, to\nsupport post-reflection, helping with goal refinement\nor adjustment.\nD. System Structure\nThe system was developed as a minimum viable product\n(MVP), comprising a platform and three browser extensions\nto assist learners in externalizing their learning experiences.\nThe tools provide support ranging from the curation stage to\nsharing: (1) Story Curator allows for tagging, rating, and\nreflecting on web resources; (2) YouTube Annotator that\nenables learners to create time-linked annotations as videos\nplay, as well as tag and rate the reflections on videos. Both\nextensions focus on enhancing the curation of resources and\nfacilitating reflections during exploratory learning (see Fig. 1).\n\n--- Page 5 ---\n(3) The backend platform , mainly provides technical\ninfrastructure for API management, but it also provides a\nvisual representation of the system logic that organizes learn-\ning experience into Resources, Tags and Stories , (see Fig.2).\nLearners can generate stories of their learning experiences, as\nshown in Fig 3. (4) Learner Eye allows learners to monitor\ntheir recent activities (namely, the period since they last added\nresources and reflections, the last time new tags or learning\npaths were initiated, and the last story they created). It provides\nways to share versions of stories modified for various social\nmedia. It also offers features to control their social media use\n(See Fig. 4).\nE. Storytelling Mechanism\nUsers can generate stories after the tagged curation process\nto make sense of their experience and get AI feedback. Their\nreflections via curation tools (Fig. 1) are sent with a Prompt\nto the OpenAI API. The platform stores the generated stories\nfor use on the platform and by Learner Eye extension (Fig. 4).\nThe extension re-generates a version of the last story for the\ncontext of a social media platform. For example, if the user\nis on X (previously Twitter), it will modify the last learning\nstory created in the platform as a series of numbered posts, or\na \u2018Thread\u2019, copied to the clipboard (see Fig.4 and Fig.5). It is\nnoted that story quality depends on the curation process.\nThe general structure of a story, as stored on the platform,\nfollows the format below:\nTitle of a story\nListing of users\u2019 reflections\nKeywords for overall reflections\nAI-Feedback\nTo achieve this structure, the prompt was iteratively refined\nto generate a learner-authored or first-person story, avoiding\nsuperficial or general advice (e.g., referring to searching for a\nsolution on Stack Overflow).\nF . Bridging Fragmented Learning via Tool-Mediated Work-\nflows: From Curation to Sharing\nThe curation tools aligns with learners\u2019 practices and prefer-\nences for informal exploration. The tools support them during\nthis curation phase by offloading their intentions, questions,\nand notes. They can also rate resources for later evaluation.\nTags allow them to initiate learning paths, keeping track of\nsimulationous learning experiences that occasionally inter-\nleave. To manage experiences, the tools offer a mechanism\nto monitor current activity to pick up where the last curation\nleft off immediately.\nFurther, the system can render a radar chart via the Learner\nEye options page, showing the number of resources on each\ntag. Allowing learners to evaluate their overall learning. The\nplatform enables learners to storytell their learning experiences\nwith generated feedback. Then Learner Eye extension allow\nlearners to share modified versions of stories for social media,while also providing tools to manage the excessive social\nmedia use and nudge for learning.\nThe system allows learners to effortlessly export selected\nlearning experiences to GitHub (See Fig. 6 and Fig. 7 ).\nThe repository name is the tag, the README file contains\nthe story, and the curation processes are organised as MD\nfiles with learner reflections timestamped. This feature nudges\npractice by giving a uniform structure and streamlining and\nscaffolding the transition to practice, tackling an issue reported\nby learners in prior research.\nIV. M ETHOD\nOur approach aligns with the Research-through-Design\nmethodology [85]: we developed a system to explore the\n\"wicked\" challenge [86] of supporting self-regulation in infor-\nmal programming learning. Such challenges lack a single op-\ntimal solution and instead demand context-sensitive responses\nthat can vary in effectiveness. As part of this approach, we\nfocused on a specific population: programming learners who\nare regular social media users, to reflect the design problem\u2019s\ncontextual nature and ground our intervention in actual learner\npractices.\nAll participants were self-reported programming learners\nwho regularly use social media in their everyday lives. Three\nquantitative scales and a qualitative survey were used to\nexamine users\u2019 characteristics, perceptions of the system\u2019s\noverall usability, and feedback on specific features in relation\nto perceived aid to their self-regulation. We detail the study\nprocedure in this section.\nA. Participant Recruitment\nWe recruited 15 informal programming learners through\nProlific [88] (n = 14) and social media platforms (n = 1).\nInitially, we attempted to recruit participants via social media\nvia a recruiting survey; although several expressed interest\n(n=42), only one ultimately responded to follow-up emails. All\n15 participants self-identified as programming learners who\nregularly use social media. Their programming experience\nranged from novices to more experienced learners and pro-\nfessionals. All participants were compensated fairly for their\ntime.\nB. Procedure\nParticipants were guided through the tool installation via\nemail instructions , blog posts and three surveys: recruit-\nment, guidance, and evaluation. They were asked to use the\nthree web extensions, Story Curator, YouTube Annotator, and\nLearner Eye, alongside the leading platform (Link removed).\nThey were encouraged to (1)tag and reflect on programming\nlearning resources of their choice, (2)generate learning stories\nabout their learning experiences, and (3)explore other features\n(e.g., sharing stories and viewing visualizations). They were\nasked to generate at least one story that combined a minimum\nof three resources, along with reflections on those resources.\nThe leading researcher reviewed each survey submission\nto verify the inclusion of a genuine story based on curated\n\n--- Page 6 ---\nFig. 1. Story Curator and YouTube Annotator extensions. (A) The Story Curator extension allows learners to tag, rate, and reflect on online resources,\nhelping with organization and immediate offloading. (B) The YouTube Annotator extension allows timestamped reflections while watching videos, displaying\nreflections as balloons. Clicking a balloon jumps to that part of the video. These tools enable in situ reflection during exploratory learning (R1, R2). Tagged\nreflections can be converted into stories, each tag representing a new story.\nFig. 2. The platform primarily stores data and manages API connections\nbetween front-end extensions and OpenAI. It also displays resources from\nthe curation process and allows for story creation through a dedicated tab in\nthe left sidebar.\nresources, serving as minimal evidence of engagement with\nthe system. This process was supported by Google Analytics\nto check the number of actual participants. Unsatisfactory\nsubmissions (i.e., submitting a survey without pasting a story)\nwere returned to Prolific for revision and to include a proper\nstory based on curation and engagement with the system\u2019s\nfeatures.\nC. Instruments Rationale\nAfter the trial, participants completed a quantitative and\nqualitative survey. The quantitative component focused on\nparticipant characteristics and overall system usability, using\nFig. 3. Learners can generate stories of their learning experiences via the\nstories tab in the left sidebar. The shown menu lists the learners\u2019 created tags\n(or learning paths). Each tag represents a curation process, stored reflections,\nand links to resources, such as anchors to multiple YouTube segments they\npreviously curated within a tag.\nvalidated scales: the General Self-Efficacy Scale (8 items) [79],\nthe Sense of Coherence scale (13 items) [82], [83] (SoC),\nand the User Experience Scale Short version (8 items) [84]\n(UEQ-S). The qualitative component explored participants\u2019\nperceptions of the system\u2019s key features and its perceived\nimpact on their self-regulation.\nWe used the validated self-efficacy and SoC due to chal-\nlenges recruiting learners through social media; many com-\npleted the surveys but did not respond to follow-up emails.\nThis highlighted how costly and difficult it can be to sustain\nparticipant engagement remotely. We included these scales\nto characterise our sample better and support future research\nand replication. While the sample size is small, we hope this\nprovides a more in-depth description of our participants. We\nelaborate on these scales as follow:\n\n--- Page 7 ---\nFig. 4. Learner Eye extension aims to help learners monitor their own curation\nand storytelling activity; it also provides a mechanism to share stories on social\nmedia and control excessive use on those platforms. The screenshot shows a\npop-up when learners visit social media platforms, depicting recent activity.\nFig. 5. A learning story shared to X using Learner Eye. The author made\nsure to protect the associated X profile for anonymity\n1) Sense of Coherence: The Sense of Coherence Scale\nmeasures three constructs: how individuals perceive life as\ncomprehensible, manageable, and meaningful [80]. A higher\nsense of coherence score is associated with better stress\nmanagement and overall well-being. Research indicates that\nindividuals with high SoC perceive challenges as navigable,\nwhereas those with lower SoC are more likely to adopt\navoidant strategies , such as procrastination [81].\n2) Self-efficacy: Self-efficacy refers to an individual\u2019s belief\nin their capability to achieve goals [87]. Prior research shows\nthat learners with high self-efficacy tend to approach tasks with\ngreater persistence. In contrast, those with low self-efficacy\noften doubt their skills, avoid tasks perceived as risky, and are\nmore likely to disengage [89].\nThese two scales may reveal variation and potential corre-\nlations in learners\u2019 approaches to self-directed programming\ntasks within our tools. However, given the small sample size,\nwe do not treat such findings as reliable. Nor do we claim\nthat learners with specific psychological characteristics will\nconsistently respond to the design in a particular way. Instead,\nthe scales offer quantitative documentation of our sample,\nsupport the interpretation of participant feedback, and provide\na foundation for future research.\nFig. 6. Options page of Story Curator allow exporting to GitHub. Learners\ncan export learning to GitHub, where reflection and resources are organised\nas MD files. The story, if generated, will be in the readme file. If not yet\ncreated, the number of resources and their times will be added, noting that\nlearning is in progress.\nD. Analyses\nWe used descriptive statistics to summarize results from\nthe SoC, Self Efficacy, and UEQ-S scales, calculating mean\n(M) and standard deviation (SD) to characterize the sample\nand support replication. Qualitative responses to open-ended\nquestions were analysed using inductive thematic analysis\nto identify recurring themes in learners\u2019 experiences and\nfeedback.\nV. R ESULTS\nWe divide our findings into two main sections. The first sec-\ntion describes user characteristics to help replicate our results\nand offer insights for future research, especially concerning\nlow engagement in system trials, which can be challenging\nand costly. The second section presents users\u2019 feedback on\nthe system and their opinions on its effectiveness in supporting\nself-regulation.\nA. Users\u2019 Characteristics\nFifteen informal programming learners (7 females) partici-\npated in the study. Their self-reported programming experience\n\n--- Page 8 ---\nFig. 7. Screenshot of exported learning to GitHub. Author made sure to make\nthe repository private for anonymity.\nFig. 8. The UEQ-S scale shows a slightly above average positive user\nexperience for the overall system experience.\nranged from novice to advanced. The average age was 30.7\nyears (SD = 8.05), with a range from 19 to 46.\nOn the self-efficacy scale (5-point), participants averaged\n3.88 (SD = 0.49), suggesting relatively close or similar per-\nceptions of self-efficacy across the sample. In contrast, scores\non the SoC (maximum score: 91) were more dispersed (M\n= 53.42, SD = 8.35, range: 43 to 72), reflecting broader\nindividual differences in sense of coherence.\nB. System Feedback1) Overall User Experience: To assess whether the system\nis usable overall, participants completed the UEQ-S, where\nscores range from -3 (horribly bad) to +3 (extremely good).\nThe average score was 0.54 (SD = 1.29), indicating slightly\npositive experiences, especially given that the system is an\nunpolished MVP, with wide variability (range: -1.75 to 3).\n2) User Feedback on System Elements: To evaluate partici-\npants\u2019 perceptions of specific system features, we administered\n17 5-points agreement-scale items assessing the extent to\nwhich these features aligned with the intended design goals.\nSelected survey items are presented below:\n\u2022\u201cThe system helps me reflect effectively on my learning\nexperiences\u201d.\n\u2022\u201cThe story generation feature enables me to summarize\nand build on my learning\u201d.\n\u2022\u201cThe ability to share stories on social media enhances\nmy motivation and engagement\u201d.\n\u2022\u201cThe tagging feature helps me organize and navigate my\nlearning pathways\u201d.\n\u2022\u201cThe web extensions are easy to use and integrate into\nmy daily learning routine\u201d.\n\u2022\u201cThe story helps identify actionable next steps\u201d.\nFor the seven items assessing overall system features, the\nmean rating was 3.35 (SD = 0.58). The five items related to\nthe browser extensions yielded a slightly higher mean of 3.47\n(SD = 0.70).\nThe storytelling feature (five items) received the highest\nagreement among the components evaluated, with a mean of\n3.73 (SD = 0.78) across five items.\n3) Perceived Support for Self-Regulation : We used a 3-\npoint scale on six items to investigate the perceived impact\nof the system on participants\u2019 self-regulation in informal\nlearning (See Fig. 9). This simplified scale was chosen to\nreduce response fatigue, particularly following the preceding\nmulti-scale instruments, and to prompt clearer, more decisive\njudgments about impact.\nParticipants\u2019 responses across all items were generally pos-\nitive, notably, no one selecting \u201cdisagree\u201d for any statement.\nEleven participants agreed that the system helps them easily\nresume previous learning sessions, while four were neutral.\nThirteen participants agreed that it provides helpful context\nor reminders to pick up where they left off, with two re-\nsponding neutrally. Twelve participants agreed that the system\nencourages reflection on earlier learning goals, and the same\nnumber agreed that it helps refine goals based on progress and\nchallenges; three participants were neutral on each of these\nitems.\nFewer participants agreed that the system supports adapting\nlearning strategies over time, only six indicated agreement,\nwhile nine were neutral. A similar distribution was observed\nfor the item about organizing or structuring learning activities,\nwhere nine participants agreed and six responded neutrally.\nC. Qualitative Responses\nOur survey included several open-ended questions. Exam-\nples of open-ended questions used:\n\n--- Page 9 ---\nFig. 9. Six items focused on perceived support for self-regulation.\n\u2022\u201cThink about your past learning experiences without the\nhelp of tools. Now, tell us: how confident do you feel\nabout achieving your learning goals with the help of such\na system?\u201d\n\u2022\u201cDo the connections between tags, resources, and stories\nfeel natural and intuitive?\u201d\n\u2022\u201cDo you think the storytelling approach can effectively\nguide you toward achieving your learning goals?\u201d\n\u2022\u201cWhat did you like most about the system and its tools?\u201d\nWe categorized the open-ended responses into three themes:\npositive experiences, negative experiences, and user sugges-\ntions.\n1) Positive Experiences: Most of the positive feedback\nfocused on the curation affordances and the generated stories,\nwhich participants described as motivating and empowering.\nThese features were appreciated for combining personal reflec-\ntions with added insights, helping users track their learning\nprogress and structure their efforts more effectively. The\nfollowing quotes highlight several ways in which participants\nexperienced the system as positively supporting their learning.\nLearners appreciated the clarity :\u201cThat\u2019s been the most\nuseful feature for me so far. The keyword recognition from\nthe resources and the way it breaks them down step by step\ninto stories. . . it\u2019s just very well done\u201d.\nOthers valued the structured nature of the experience: \u201cThe\ntools are not cutting-edge technologies, but at least they offer\nyou a well structured method of learning and feedback which\nI found really helpful\u201d.\nThe storytelling approach was seen as adding meaningful\ncontext: \u201c... the storytelling approach can be highly effective\n(. . . ) makes learning more memorable by providing relatable\nand meaningful contexts\u201d.\nExternalization helped learners maintain motivation: \u201cSee-\ning your learning journey as a narrative helps you stay\nconnected to your goals, even during challenging times\u201d .\nCombining reflections with added AI-insights was pos-\nitively received: \u201c... stories are very helpful and cool. It\ncombines nicely and gives interesting information when click\non the details\u201d .\nSome participants suggested that the system can help use\ntime more effectively :\u201cIt would make the learning process\nmore effective and less time consuming, which is great\u201d .A potential boost in self-efficacy reported: \u201cSuch a system\nwould make it easier for me to recall what I learned earlier\nand refresh my memory, simplifying my learning and thus\nincreasing my confidence in achieving my learning goals\u201d.\n2) Negative Experiences: Negative responses often\nstemmed from a lack of engagement in real learning activities\nor incomplete exploration of the system\u2019s features. However,\nthe most critical feedback centred on the Learner Eye web\nextension, which integrates features to self-control social\nmedia use and handle sharing stories to social media.\nSome participants perceived them as interrupting, and they\nexpressed reluctance toward social sharing. One participant\nexplained, \u201cI did not use the story-sharing feature; I don\u2019t\nthink I\u2019ve seen it. I would not use such a feature because I am\nnot keen on sharing my learning stories with others\u201d and\u201cI\nhave not used the feature of sharing stories on social networks\nlike Instagram because for me that is very private and I prefer\nto do it myself\u201d .\nFurther concerns were raised about self-control feature (see\nFig. 4) perceived as disruptive :\u201cI am not yet convinced that\nI would achieve my goals with its help, I was often disturbed\nby pop-ups when I was focused on tasks\u201d . Some participants\nalso struggled with interface navigation. For instance, one\nremarked, \u201cI would have liked the YouTube annotation if I\ncould have figured out how to find it again once I was done\nwith it\u201d . Another raised issues of privacy : \u201c(. . . ) how much\ninformation the plugins have access to, and what they can do\nwith it\u201d.\n3) Suggestions: Some participants provided suggestions,\nfocusing on the system category, integration, and personali-\nsation. One participant proposed a shift in how the system\nis framed and used: \u201cI believe the system should be less of\na reflection tool and more of a learning notebook, where one\ncan make notes as they learn about what they learn, where to\nfind materials on the topic, or make bookmarks\u201d.\nAnother emphasized the need to simplify the setup :\u201cI\nwould prefer only 1 add-on with all options, not 3\u201d. Specific\nsuggestions were also made to improve the way video annota-\ntions feed into story generation, \u201cI think stories should handle\nvideo reflections differently; they could provide them in a list\nwith actual links to the videos at the bookmarked moment\u201d.\nFurther, there was interest in adding more control to the\nstorytelling element: \u201cMaybe give two or three story options\nso that the user can choose the one they like better\u201d.\nVI. D ISCUSSION\nIn this paper, our focus was on demonstrating storytelling as\na design element within a self-regulation tool. Findings from\nboth quantitative and qualitative data indicate the potential of\nthis approach to support self-regulation. In this section, we\nreflect on the design decisions we made (addressing RQ1),\nhighlight key findings from user feedback on the system\n(addressing RQ2), and conclude with design consideration for\nfuture work (addressing RQ3).\n\n--- Page 10 ---\nA. Integrating Storytelling into Self-Regulation Tool Design\n(RQ1)\nBy a storytelling-centric approach, we mean tools inten-\ntionally designed to externalise learning experiences. Our\nsystem organize informal programming learners\u2019 experience\naround three elements, Resources, Tags, and Stories, which\ncorrespond to three levels of learner engagement: curation,\norganisation, and externalisation. This framing makes learning\nvisible, evaluable, and shareable. This approach aligns with\nprior work discussed in the Related Work section; it explicitly\nextends the COIL model proposed by Gao et al. [3] and draws\ninspiration from the design suggestions provided by Alghamdi\net al. [6], making it suitable for describing the experience\nof self-regulation for informal programming learners in social\nmedia.\nThese elements form a conceptual design for integrating sto-\nrytelling into self-regulation support: Resources enable content\ncollection (e.g., annotating YouTube segments), Tags organise\nmaterials into evolving learning paths, and Stories synthesise\nactivity into personal narratives. The design addresses gaps\nin existing tools discussed in related works, particularly the\nlack of support for reflection, continuity, and learner-driven\nsynthesis.\nFraming informal learning activity around curation, or-\nganisation, and externalisation offers a transferable structure\nfor embedding storytelling into tool design to support self-\nregulation in informal contexts.\nB. Perceived Value and Friction Points (RQ2)\nQuantitative and qualitative findings showed that partici-\npants found the system usable and valuable for supporting their\nlearning self-regulation. The integration of learners\u2019 reflec-\ntions with AI-generated feedback was appreciated. Participants\ndescribed various ways in which the stories supported their\nlearning, primarily by consolidating fragmented activities into\na cohesive structure, increasing clarity, adding meaning, en-\nhancing productivity, and saving time. Most learners found the\ncuration process (transforming tagged resources into stories)\nclear and sensible.\nLearners also favoured tools that support precise, in-the-\nmoment interactions, such as in YouTube Annotation, which\nallows marking specific moments within a video, over tools\nthat operate at the level of entire resources (e.g., tagging or\ncurating whole videos or articles, as in the Story Curator).\nThis suggests a preference for more granular, context-sensitive\nsupport during curation stage.\nOn the other hand, friction emerged around interface com-\nplexity (the use of multiple extensions), concerns about social\nsharing, and negative feedback on self-control features. Most\nparticipants preferred private use, viewing storytelling as a\npersonal sensemaking tool more than a shared artefact.\nC. Considerations for Future Work (RQ3)\nIn future work, we are interested in wrapping the\nstorytelling-centric conceptual design with a more polished in-\nterface and introducing more fine-grained curation capabilitiesand control over generated stories. Also at the organization\nstage, we can add more control over tags, such as merging\nmultiple learning paths , connect them or branch. The goal is\nto increase learners\u2019 autonomy in how they interact with and\norganize resources, learning paths and stories.\nAdditionally, we plan to move self-control and sharing\nfeatures into a control panel or dashboard. Such functionality\nin personal learning contexts should remain optional and user-\ninitiated. Although we offered mechanisms for control or\nopting out, these were initially enforced\u2014an approach that\nwas received negatively. Participants expressed concerns, both\nimplicitly and explicitly, about potential violations of privacy\nand autonomy. This suggests that self-regulation cannot be\neffectively supported through imposed constraints, but rather\nthrough carefully designed, learner-driven mechanisms.\nWe believe there is significant room for future work to in-\nvestigate how a storytelling-centric approach could inform the\ndesign of AI-augmented tools that support self-regulation\u2014by\nassisting learners across key stages of informal learning (cura-\ntion, organization, storytelling, and sharing), while preserving\ntheir agency and autonomy.\nD. Limitations\nThis study is limited by a small sample size (n = 15) and a\nshort evaluation period. Although tasks were self-paced, most\nparticipants appeared to complete the surveys with minimal\neffort, likely motivated by the task reward. While validated\nscales (SoC, Self-Efficacy, UEQ-S) may strengthen the study\nand offer well-rounded insights, we did not, within the scope\nof this paper, extend to claim any causal effects based on\nthe feedback interpretation. A longer-term study is needed to\nexamine potential effects on learning outcomes and explore\ndifferential impacts across learner profiles.\nMoreover, our work focused on social media users. While\na vast population, we recognise that our approach may not\nbenefit those who are not social media users or are not\ndependent on online resources, acknowledging those who\nprefer more structured and instructor-led approaches to learn\nto program.\nVII. C ONCLUSION\nThis paper demonstrated a storytelling-centric approach to\ndesigning for self-regulation. Our findings indicate that this\napproach integrates well with informal learning experiences. It\nholds potential, enabling learners to reconnect with fragmented\nprogress, clarify goals, and engage in sustained reflection.\nParticipants valued the fine-grained curation of videos and\nperceived the storytelling element as adding clarity, structure,\nand meaning to their experience. On the other hand, the\nsharing feature was largely ignored during the trial, and\nsome learners explicitly criticized the self-control aspects.\nThis study contributes a conceptual design illustrating how\nstorytelling can be integrated into a self-regulation solution for\ninformal programming learners, highlighting features that were\npositively perceived as well as those that were less preferred.\n\n--- Page 11 ---\nREFERENCES\n[1] S. S. Alghamdi, C. Bull, and A. Kharrufa, \u2018Exploring the Support for\nSelf-Regulation in Adult Online Informal Programming Learning: A\nScoping Review\u2019, in Proceedings of the 2023 Conference on Innovation\nand Technology in Computer Science Education V . 1, Turku Finland:\nACM, Jun. 2023, pp. 361\u2013367. doi: 10.1145/3587102.3588811.\n[2] R. Chaudhury, P. J. Guo, and P. K. Chilana, \u2018\u201cThere\u2019s no way to keep\nup!\u201d: Diverse Motivations and Challenges Faced by Informal Learners\nof ML\u2019, in 2022 IEEE Symposium on Visual Languages and Human-\nCentric Computing (VL/HCC), Roma, Italy: IEEE, Sep. 2022, pp. 1\u201311.\ndoi: 10.1109/VL/HCC53370.2022.9833100.\n[3] G. Gao, F. V oichick, M. Ichinco, and C. Kelleher, \u2018Exploring Program-\nmers\u2019 API Learning Processes: Collecting Web Resources as External\nMemory\u2019, in 2020 IEEE Symposium on Visual Languages and Human-\nCentric Computing (VL/HCC), Dunedin, New Zealand: IEEE, Aug.\n2020, pp. 1\u201310. doi: 10.1109/VL/HCC50065.2020.9127274.\n[4] M. Beth Kery and B. A. Myers, \u2018Exploring exploratory programming\u2019,\nin 2017 IEEE Symposium on Visual Languages and Human-Centric\nComputing (VL/HCC), Raleigh, NC: IEEE, Oct. 2017, pp. 25\u201329. doi:\n10.1109/VLHCC.2017.8103446.\n[5] \u2018Stack Overflow Developer Survey 2024\u2019. [Online]. Available: https:\n//survey.stackoverflow.co/2024/. [Accessed: 7 May 2025].\n[6] S. S. Alghamdi, C. Bull, and A. Kharrufa, \u2018Thematic Analysis of\nSelf-Regulation Narratives in Textual Posts by Informal Programming\nLearners on Social Media\u2019, in 2024 IEEE Symposium on Visual Lan-\nguages and Human-Centric Computing (VL/HCC), Liverpool, United\nKingdom: IEEE, Sep. 2024, pp. 223\u2013235. doi: 10.1109/VL/HCC60511.\n2024.00033.\n[7] M. B. Kery, B. E. John, P. O\u2019Flaherty, A. Horvath, and B. A. Myers,\n\u2018Towards Effective Foraging by Data Scientists to Find Past Analysis\nChoices\u2019, in Proceedings of the 2019 CHI Conference on Human Factors\nin Computing Systems, Glasgow Scotland Uk: ACM, May 2019, pp.\n1\u201313. doi: 10.1145/3290605.3300322.\n[8] N. R. Boyer, S. Langevin, and A. Gaspar, \u2018Self direction & construc-\ntivism in programming education\u2019, in Proceedings of the 9th ACM\nSIGITE conference on Information technology education - SIGITE \u201908,\n2008. doi: 10.1145/1414558.1414585.\n[9] D. Lambton-Howard, P. Olivier, V . Vlachokyriakos, H. Celina, and A.\nKharrufa, \u2018Unplatformed Design: A Model for Appropriating Social\nMedia Technologies for Coordinated Participation\u2019, in Proceedings of\nthe 2020 CHI Conference on Human Factors in Computing Systems,\n2020. doi: 10.1145/3313831.3376179.\n[10] N. Dabbagh and A. Kitsantas, \u2018The role of social media in self-regulated\nlearning\u2019, Int. J. Web Based Communities, vol. 9, no. 2, p. 256, 2013,\ndoi: 10.1504/IJWBC.2013.053248.\n[11] R. Chaudhury and P. K. Chilana, \u2018Designing Visual and Interactive Self-\nMonitoring Interventions to Facilitate Learning: Insights from Informal\nLearners and Experts\u2019, IEEE Trans. Vis. Comput. Graph., pp. 1\u201312,\n2024, doi: 10.1109/TVCG.2024.3366469.\n[12] P. K. Chilana, R. Singh, and P. J. Guo, \u2018Understanding Conversational\nProgrammers: A Perspective from the Software Industry\u2019, in Proceedings\nof the 2016 CHI Conference on Human Factors in Computing Systems,\nSan Jose California USA: ACM, May 2016, pp. 1462\u20131472. doi:\n10.1145/2858036.2858323.\n[13] D. Loksa and A. J. Ko, \u2018The Role of Self-Regulation in Program-\nming Problem Solving Process and Success\u2019, in Proceedings of the\n2016 ACM Conference on International Computing Education Re-\nsearch, Melbourne VIC Australia: ACM, Aug. 2016, pp. 83\u201391. doi:\n10.1145/2960310.2960334.\n[14] J. Prather, B. A. Becker, M. Craig, P. Denny, D. Loksa, and L. Mar-\ngulieux, \u2018What Do We Think We Think We Are Doing?: Metacognition\nand Self-Regulation in Programming\u2019, in ICER 2020 - Proceedings\nof the 2020 ACM Conference on International Computing Education\nResearch, Association for Computing Machinery, 2020, pp. 2\u201313. doi:\n10.1145/3372782.3406263.\n[15] J. Prather et al., \u2018First Things First: Providing Metacognitive Scaffolding\nfor Interpreting Problem Prompts\u2019, in Proceedings of the 50th ACM\nTechnical Symposium on Computer Science Education, Minneapo-\nlis MN USA: ACM, Feb. 2019, pp. 531\u2013537. doi:10.1145/3287324.\n3287374.\n[16] L. Silva, A. Gomes, and A. Mendes, \u2018Investigating Students\u2019 Usage of\nSelf-regulation of Learning Scaffoldings in a Computer-based Program-\nming Learning Environment\u2019, in Proceedings of the 55th ACM TechnicalSymposium on Computer Science Education V . 1, Portland OR USA:\nACM, Mar. 2024, pp. 1244\u20131250. doi: 10.1145/3626252.3630885.\n[17] M. Manso-Vazquez, M. Caeiro-Rodriguez, and M. Llamas-Nistal, \u2018An\nxAPI Application Profile to Monitor Self-Regulated Learning Strate-\ngies\u2019, IEEE Access, vol. 6, pp. 42467\u201342481, 2018, doi: 10.1109/AC-\nCESS.2018.2860519.\n[18] R. P. Alvarez, I. Jivet, M. Perez-Sanagustin, M. Scheffel, and K. Verbert,\n\u2018Tools Designed to Support Self-Regulated Learning in Online Learning\nEnvironments: A Systematic Review\u2019, IEEE Trans. Learn. Technol., vol.\n15, no. 4, pp. 508\u2013522, Aug. 2022, doi: 10.1109/TLT.2022.3193271.\n[19] P. Dourish, \u2018The Appropriation of Interactive Technologies: Some\nLessons from Placeless Documents\u2019, Comput. Support. Coop. Work\nCSCW, vol. 12, 4, pp. 465\u2013490, 2003, doi: 10.1023/a:1026149119426.\n[20] F. Tosi, \u2018From User-Centred Design to Human-Centred Design and\nthe User Experience\u2019, in *Design for Ergonomics*, A. Author, Ed.,\nSpringer Series in Design and Innovation, vol. 2. Cham, Switzerland:\nSpringer International Publishing, 2020, pp. 47\u201359. [Online]. Available:\nhttps://doi.org/10.1007/978-3-030-33562-5_3\n[21] A. Nguyen, J. L\u00e4ms\u00e4, A. Dwiarie, and S. J\u00e4rvel\u00e4, \u2018Lifelong learner needs\nfor human-centered self-regulated learning analytics\u2019, Inf. Learn. Sci.,\nvol. 125, no. 1/2, pp. 68\u2013108, Jan. 2024, doi: 10.1108/ILS-07-2023-\n0091.\n[22] A. Alaboudi and T. D. LaToza, \u2018An Exploratory Study of Live-Streamed\nProgramming\u2019, in 2019 IEEE Symposium on Visual Languages and\nHuman-Centric Computing (VL/HCC), Memphis, TN, USA: IEEE, Oct.\n2019, pp. 5\u201313. doi: 10.1109/VLHCC.2019.8818832.\n[23] M. B. Garcia, I. C. Juanatas, and R. A. Juanatas, \u2018TikTok as a Knowl-\nedge Source for Programming Learners: a New Form of Nanolearn-\ning?\u2019, IEEE Xplore, pp. 219\u2013223, 2022, doi:10.1109/ICIET55102.2022.\n9779004.\n[24] E. Caminotti and J. Gray, \u2018The effectiveness of storytelling on adult\nlearning\u2019, J. Workplace Learn., vol. 24, no. 6, pp. 430\u2013438, Aug. 2012,\ndoi: 10.1108/13665621211250333.\n[25] H. B. Christensen, \u2018A story-telling approach for a software engineering\ncourse design\u2019, in Proceedings of the 14th annual ACM SIGCSE confer-\nence on Innovation and technology in computer science education, Paris\nFrance: ACM, Jul. 2009, pp. 60\u201364. doi: 10.1145/1562877.1562901.\n[26] R. E. Landrum, K. Brakke, and M. A. McCarthy, \u2018The pedagogical\npower of storytelling.\u2019, Scholarsh. Teach. Learn. Psychol., vol. 5, no. 3,\npp. 247\u2013253, Sep. 2019, doi: 10.1037/stl0000152.\n[27] G. M. Fern\u00e1ndez-Nieto, V . Echeverria, R. Martinez-Maldonado, and\nS. B. Shum, \u2018YarnSense: Automated Data Storytelling for Multimodal\nLearning Analytics\u2019.\n[28] P. Wuilmart, E. S\u00f6derberg, and M. H\u00f6st, \u2018Programmer Stories, Stories\nfor Programmers: Exploring Storytelling in Software Development\u2019, in\nCompanion Proceedings of the 7th International Conference on the Art,\nScience, and Engineering of Programming, Tokyo Japan: ACM, Mar.\n2023, pp. 68\u201375. doi: 10.1145/3594671.3594677.\n[29] J. Allen and C. Kelleher, \u2018Exploring the impacts of semi-automated\nstorytelling on programmers\u2019 comprehension of software histories\u2019,\nin 2024 IEEE Symposium on Visual Languages and Human-Centric\nComputing (VL/HCC), Liverpool, United Kingdom: IEEE, Sep. 2024,\npp. 148\u2013162. doi: 10.1109/VL/HCC60511.2024.00025.\n[30] M. B. Kery, M. Radensky, M. Arya, B. E. John, and B. A. Myers,\n\u2018The Story in the Notebook: Exploratory Data Science using a Literate\nProgramming Tool\u2019, in Proceedings of the 2018 CHI Conference on\nHuman Factors in Computing Systems, Montreal QC Canada: ACM,\nApr. 2018, pp. 1\u201311. doi: 10.1145/3173574.3173748.\n[31] J. Allen, \u2018Code Stories for Software Repurposing\u2019, in 2023 IEEE Sym-\nposium on Visual Languages and Human-Centric Computing (VL/HCC),\nWashington, DC, USA: IEEE, Oct. 2023, pp. 309\u2013311. doi: 10.1109/VL-\nHCC57772.2023.00063.\n[32] M.-A. Storey, A. Zagalsky, F. F. Filho, L. Singer, and D. M. German,\n\u2018How Social and Communication Channels Shape and Challenge a Par-\nticipatory Culture in Software Development\u2019, IEEE Trans. Softw. Eng.,\nvol. 43, no. 2, pp. 185\u2013204, Feb. 2017, doi: 10.1109/TSE.2016.2584053.\n[33] M. Ito et al. , \u2018Connected learning: An agenda for research and design\u2019,\n2014. ISBN-13: 978-0-9887255-0-8\n[34] M. X. Liu, A. Kittur, and B. A. Myers, \u2018Crystalline: Lowering the\nCost for Developers to Collect and Organize Information for Deci-\nsion Making\u2019, in CHI Conference on Human Factors in Computing\nSystems, New Orleans LA USA: ACM, Apr. 2022, pp. 1\u201316. doi:\n10.1145/3491102.3501968.\n\n--- Page 12 ---\n[35] A. Kharrufa, P. Olivier, and D. Leat, \u2018Learning Through Reflection at\nthe Tabletop: A Case Study with Digital Mysteries\u2019, in Proceedings of\nEdMedia + Innovate Learning 2010, Waynesville, NC: Association for\nthe Advancement of Computing in Education (, 2010, pp. 665\u2013674.\n[36] R. Chaudhury, T. Liaqat, and P. K. Chilana, \u2018Exploring the Needs of\nInformal Learners of Computational Skills: Probe-Based Elicitation for\nthe Design of Self-Monitoring Interventions\u2019.\n[37] A. Y . Wang, R. Mitts, P. J. Guo, and P. K. Chilana, \u2018Mismatch of\nExpectations\u2019, in Proceedings of the 2018 CHI Conference on Human\nFactors in Computing Systems, 2018. doi: 10.1145/3173574.3174085.\n[38] M. R\u00f5\u00f5m, M. Lepp, and P. Luik, \u2018Dropout Time and Learners\u2019 Perfor-\nmance in Computer Programming MOOCs\u2019, Educ. Sci., vol. 11, 10, p.\n643, 2021, doi: 10.3390/educsci11100643.\n[39] A. Hawlitschek, V . K\u00f6ppen, A. Dietrich, and S. Zug, \u2018Drop-out in\nprogramming courses \u2013 prediction and prevention\u2019, J. Appl. Res. High.\nEduc. Ahead\u2013Print, 2019, doi: 10.1108/jarhe-02-2019-0035.\n[40] L. E. Margulieux, B. B. Morrison, and A. Decker, \u2018Reducing withdrawal\nand failure rates in introductory programming with subgoal labeled\nworked examples\u2019, Int. J. STEM Educ., vol. 7, no. 1, p. 19, Dec. 2020,\ndoi: 10.1186/s40594-020-00222-7.\n[41] D. F. O. Onah and J. E. Sinclair, \u2018Assessing Self-Regulation of Learning\nDimensions in a Stand-alone MOOC Platform\u2019, Int. J. Eng. Pedagogy\nIJEP, vol. 7, no. 2, p. 4, May 2017, doi: 10.3991/ijep.v7i2.6511.\n[42] G. Schraw, K. J. Crippen, and K. Hartley, \u2018Promoting Self-Regulation\nin Science Education: Metacognition as Part of a Broader Perspective\non Learning\u2019, Res. Sci. Educ., vol. 36, no. 1, pp. 111\u2013139, Mar. 2006,\ndoi: 10.1007/s11165-005-3917-8.\n[43] L. Silva, A. Mendes, A. Gomes, and G. Fortes, \u2018What Learning Strate-\ngies are Used by Programming Students? A Qualitative Study Grounded\non the Self-regulation of Learning Theory\u2019, ACM Trans. Comput. Educ.,\nvol. 24, no. 1, pp. 1\u201326, Mar. 2024, doi: 10.1145/3635720.\n[44] B. J. Zimmerman, \u2018Attaining self-regulation: A social cognitive perspec-\ntive\u2019, in Handbook of self-regulation, Elsevier, 2000, pp. 13\u201339.\n[45] G. Ciolacu, C. Haas, and M. Hall, \u2018Rightsizing: Understanding Novice,\nCasual Learners of Programming\u2019, in Proceedings of the 56th ACM\nTechnical Symposium on Computer Science Education V . 2, Pittsburgh\nPA USA: ACM, Feb. 2025, pp. 1421\u20131422. doi: 10.1145/3641555.\n3705239.\n[46] A. B. Morrison and L. L. Richmond, \u2018Offloading items from memory:\nindividual differences in cognitive offloading in a short-term memory\ntask\u2019, Cogn. Res. Princ. Implic., vol. 5, no. 1, p. 1, Dec. 2020, doi:\n10.1186/s41235-019-0201-4.\n[47] S. J. Gilbert, A. Boldt, C. Sachdeva, C. Scarampi, and P.-C. Tsai,\n\u2018Outsourcing Memory to External Tools: A Review of \u201cIntention Of-\nfloading\u201d\u2019, Psychon. Bull. Rev., vol. 30, no. 1, pp. 60\u201376, Feb. 2023,\ndoi: 10.3758/s13423-022-02139-4.\n[48] H. S. Meyerhoff, S. Grinschgl, F. Papenmeier, and S. J. Gilbert,\n\u2018Individual differences in cognitive offloading: a comparison of intention\noffloading, pattern copy, and short-term memory capacity\u2019, Cogn. Res.\nPrinc. Implic., vol. 6, no. 1, p. 34, Dec. 2021, doi: 10.1186/s41235-021-\n00298-x.\n[49] P. K. Chilana et al., \u2018Perceptions of non-CS majors in intro program-\nming: The rise of the conversational programmer\u2019, in 2015 IEEE Sympo-\nsium on Visual Languages and Human-Centric Computing (VL/HCC),\nAtlanta, GA: IEEE, Oct. 2015, pp. 251\u2013259. doi: 10.1109/VLHCC.2015.\n7357224.\n[50] K. R. Vareberg and C. A. Platt, \u2018Harnessing the wisdom of YouTube:\nhow self-directed learners achieve personalized learning through tech-\nnological affordances\u2019, Interact. Learn. Environ., vol. 32, no. 10, pp.\n7141\u20137155, Nov. 2024, doi: 10.1080/10494820.2024.2307597.\n[51] D. Lambton-Howard, J. Kiaer, and A. Kharrufa, \u2018\u201cSocial media is their\nspace\u201d: student and teacher use and perception of features of social\nmedia in language education\u2019, Behav. Inf. Technol., vol. 40, no. 16, pp.\n1700\u20131715, Dec. 2021, doi: 10.1080/0144929X.2020.1774653.\n[52] N. Dabbagh and A. Kitsantas, \u2018Personal Learning Environments, social\nmedia, and self-regulated learning: A natural formula for connecting\nformal and informal learning\u2019, Internet High. Educ., vol. 15, no. 1, pp.\n3\u20138, Jan. 2012, doi: 10.1016/j.iheduc.2011.06.002.\n[53] T. Faas, L. Dombrowski, E. Brady, and A. Miller, \u201cLooking for Group:\nLive Streaming Programming for Small Audiences,\u201d in *Information in\nContemporary Society*, 2019, pp. 117\u2013123. doi: 10.1007/978-3-030-\n15742-5_10.\n[54] R. M. Ryan and E. L. Deci, \u2018Self-determination theory and the facili-tation of intrinsic motivation, social development, and well-being\u2019, Am.\nPsychol., vol. 55, 1, pp. 68\u201378, 2000, doi: 10.1037/0003-066x.55.1.68.\n[55] Z. Duo, J. Zhang, Y . Ren, and X. Xu, \u2018Examining self-regulation\nmodels of programming students in visual environments: A bottom-up\nanalysis of learning behaviour\u2019, Educ. Inf. Technol., vol. 30, no. 4, pp.\n5229\u20135249, Mar. 2025, doi: 10.1007/s10639-024-13016-z.\n[56] P. Gu, J. Wu, Z. Cheng, Y . Xia, M. Cheng, and Y . Dong, \u2018Scaffolding\nself-regulation in project-based programming learning through online\ncollaborative diaries to promote computational thinking\u2019, Educ. Inf.\nTechnol., Feb. 2025, doi: 10.1007/s10639-025-13367-1.\n[57] G. Cheng, D. Zou, H. Xie, and F. L. Wang, \u2018Exploring differ-\nences in self-regulated learning strategy use between high- and low-\nperforming students in introductory programming: An analysis of\neye-tracking and retrospective think-aloud data from program com-\nprehension\u2019, Comput. Educ., vol. 208, p. 104948, Jan. 2024, doi:\n10.1016/j.compedu.2023.104948.\n[58] K. Falkner, R. Vivian, and N. J. G. Falkner, \u2018Identifying computer\nscience self-regulated learning strategies\u2019, in Proceedings of the 2014\nconference on Innovation & technology in computer science education\n- ITiCSE \u201914, Uppsala, Sweden: ACM Press, 2014, pp. 291\u2013296. doi:\n10.1145/2591708.2591715.\n[59] D. J. Ferreira, D. S. Campos, and A. C. Gon\u00e7alves, \u2018Regulatory\nStrategies for Novice Programming Students\u2019, in Computer Supported\nEducation, vol. 2052, B. M. McLaren, J. Uhomoibhi, J. Jovanovic, and\nI.-A. Chounta, Eds., in Communications in Computer and Information\nScience, vol. 2052. , Cham: Springer Nature Switzerland, 2024, pp.\n136\u2013159. doi: 10.1007/978-3-031-53656-4_7.\n[60] R. P\u00e9rez-\u00c1lvarez, J. Maldonado-Mahauad, and M. P\u00e9rez-Sanagust\u00edn,\n\u2018Tools to Support Self-Regulated Learning in Online Environments:\nLiterature Review\u2019, in Lifelong Technology-Enhanced Learning, vol.\n11082, V . Pammer-Schindler, M. P\u00e9rez-Sanagust\u00edn, H. Drachsler, R.\nElferink, and M. Scheffel, Eds., in Lecture Notes in Computer Science,\nvol. 11082. , Cham: Springer International Publishing, 2018, pp. 16\u201330.\ndoi:10.1007/978-3-319-98572-5_2.\n[61] J. Broadbent, E. Panadero, J. M. Lodge, and P. Barba, \u2018Technologies\nto Enhance Self-Regulated Learning in Online and Computer-Mediated\nLearning Environments\u2019, Handb. Res. Educ. Commun. Technol., pp.\n37\u201352, 2020, doi: 10.1007/978-3-030-36119-8_3.\n[62] R. Chaudhury, \u2018Designing Interactive Self-Monitoring Tools for Informal\nLearners of Computational Skills\u2019, in 2023 IEEE Symposium on Visual\nLanguages and Human-Centric Computing (VL/HCC), Washington, DC,\nUSA: IEEE, Oct. 2023, pp. 307\u2013308. doi: 10.1109/VL-HCC57772.2023.\n00062.\n[63] U. Lyngs et al., \u2018Self-Control in Cyberspace: Applying Dual Sys-\ntems Theory to a Review of Digital Self-Control Tools\u2019, in Proceed-\nings of the 2019 CHI Conference on Human Factors in Computing\nSystems, Glasgow Scotland Uk: ACM, May 2019, pp. 1\u201318. doi:\n10.1145/3290605.3300361.\n[64] A. M. Roffarello and L. De Russis, \u2018Achieving Digital Wellbeing\nThrough Digital Self-control Tools: A Systematic Review and Meta-\nanalysis\u2019, ACM Trans. Comput.-Hum. Interact., vol. 30, no. 4, pp. 1\u201366,\nAug. 2023, doi: 10.1145/3571810.\n[65] R. Wang, A. Abusafia, A. Lakhdari, and A. Bouguettaya, \u2018The Nudg-\ning Effect on Tracking Activity\u2019, in Proceedings of the 2022 ACM\nInternational Joint Conference on Pervasive and Ubiquitous Computing,\nCambridge United Kingdom: ACM, Sep. 2022, pp. 130\u2013132. doi:\n10.1145/3544793.3560366.\n[66] Forest: Stay focused, be present. Accessed: May 03, 2025. [Online].\nAvailable: https://www.forestapp.cc/\n[67] Habitica: Gamify Your Life. Accessed: May 03, 2025. [Online]. Avail-\nable: https://habitica.com/static/home\n[68] C. Wang, \u2018Comprehensively Summarizing What Distracts Students from\nOnline Learning: A Literature Review\u2019, Hum. Behav. Emerg. Technol.,\nvol. 2022, pp. 1\u201315, Oct. 2022, doi: 10.1155/2022/1483531.\n[69] C. Yot-Dom\u00ednguez and C. Marcelo, \u2018University students\u2019 self-regulated\nlearning using digital technologies\u2019, Int. J. Educ. Technol. High. Educ.,\nvol. 14, no. 1, p. 38, Dec. 2017, doi: 10.1186/s41239-017-0076-8.\n[70] W. J. Joel, \u2018Engaging computer science education\u2019, ACM SIGCSE Bull.,\nvol. 38, no. 3, pp. 316\u2013316, Sep. 2006, doi: 10.1145/1140123.1140222.\n[71] W. J. Joel, \u2018A story paradigm for computer science education\u2019, in\nProceedings of the 18th ACM conference on Innovation and technology\nin computer science education, Canterbury England, UK: ACM, Jul.\n2013, pp. 362\u2013362. doi: 10.1145/2462476.2466526.\n\n--- Page 13 ---\n[72] A. Korhonen and M. Vivitsou, \u2018Digital Storytelling and Group Work:\nIntegrating the Narrative Approach into a Higher Education Computer\nScience Course\u2019, in Proceedings of the 2019 ACM Conference on Inno-\nvation and Technology in Computer Science Education, Aberdeen Scot-\nland Uk: ACM, Jul. 2019, pp. 140\u2013146. doi: 10.1145/3304221.3325528.\n[73] A. Horvath, \u2018Meta-Information to Support Sensemaking by Developers\u2019.\n[74] A. Horvath, A. Macvean, and B. A. Myers, \u2018Support for Long-Form\nDocumentation Authoring and Maintenance\u2019, in 2023 IEEE Symposium\non Visual Languages and Human-Centric Computing (VL/HCC), Wash-\nington, DC, USA: IEEE, Oct. 2023, pp. 109\u2013114. doi: 10.1109/VL-\nHCC57772.2023.00020.\n[75] A. Horvath, B. Myers, A. Macvean, and I. Rahman, \u2018Using Annotations\nfor Sensemaking About Code\u2019, in Proceedings of the 35th Annual ACM\nSymposium on User Interface Software and Technology, Bend OR USA:\nACM, Oct. 2022, pp. 1\u201316. doi: 10.1145/3526113.3545667.\n[76] L. Margulieux and R. Catrambone, \u2018Using Learners\u2019 Self-Explanations\nof Subgoals to Guide Initial Problem Solving in App Inventor\u2019, in\nProceedings of the 2017 ACM Conference on International Computing\nEducation Research, Tacoma Washington USA: ACM, Aug. 2017, pp.\n21\u201329. doi: 10.1145/3105726.3106168.\n[77] A. Horvath et al., \u2018Understanding How Programmers Can Use Anno-\ntations on Documentation\u2019, in CHI Conference on Human Factors in\nComputing Systems, New Orleans LA USA: ACM, Apr. 2022, pp. 1\u201316.\ndoi: 10.1145/3491102.3502095.\n[78] D. A. Kolb, Experiential Learning. Pearson Education, 2014.\n[79] New General Self-Efficacy Scale. [Online]. Available: https://sparqtools.\norg/mobility-measure/new-general-self-efficacy-scale/\n[80] N. Uzdil and Y . G\u00fcnayd\u0131n, \u2018The effect of sense of coherence on\nmindful attention awareness and academic self-efficacy in nursing\nstudents\u2019, Nurse Educ. Pract., vol. 64, p. 103429, Oct. 2022, doi:\n10.1016/j.nepr.2022.103429.\n[81] K. Konaszewski, M. Kolemba, and M. Niesiob\u02db edzka, \u2018Resilience, sense\nof coherence and self-efficacy as predictors of stress coping style among\nuniversity students\u2019, Curr. Psychol., vol. 40, no. 8, pp. 4052\u20134062, Aug.\n2021, doi:10.1007/s12144-019-00363-1.\n[82] A. Masry Herzallah and R. Makaldy, \u2018Technological self-efficacy and\nsense of coherence: Key drivers in teachers\u2019 AI acceptance and adop-\ntion\u2019, Comput. Educ. Artif. Intell., vol. 8, p. 100377, Jun. 2025, doi:\n10.1016/j.caeai.2025.100377.\n[83] Y . Salamonson, L. M. Ramjan, S. Van Den Nieuwenhuizen, L. Metcalfe,\nS. Chang, and B. Everett, \u2018Sense of coherence, self-regulated learning\nand academic performance in first year nursing students: A cluster\nanalysis approach\u2019, Nurse Educ. Pract., vol. 17, pp. 208\u2013213, Mar. 2016,\ndoi: 10.1016/j.nepr.2016.01.001.\n[84] \u2018UEQ-S\u2019, User Experience Questionnaire. [Online]. Available:\nhttps://www.ueq-online.org/\n[85] J. Zimmerman, J. Forlizzi, and S. Evenson, \u201cResearch through design\nas a method for interaction design research in HCI,\u201d in Proceedings of\nthe SIGCHI Conference on Human Factors in Computing Systems , San\nJose, California, USA: ACM, Apr. 2007, pp. 493\u2013502. doi: 10.1145/\n1240624.1240704.\n[86] \u201c What\u2019s a Wicked Problem? \u201d [Online]. Available: https:\n//www.stonybrook.edu/commcms/wicked-problem/about/What-is-a-\nwicked-problem\n[87] S. Lippke, \u201cSelf-efficacy theory,\u201d in Encyclopedia of Personality and\nIndividual Differences , V . Zeigler-Hill and T. K. Shackelford, Eds.\nCham: Springer, 2020, pp. 4722\u20134727. doi: 10.1007/978-3-319-24612-\n3_1167.\n[88] Prolific, \u201cProlific: Participant recruitment for research,\u201d [Online]. Avail-\nable: https://www.prolific.com/\n[89] F. Pajares, \u201cSelf-efficacy beliefs in academic settings,\u201d Rev. Educ. Res. ,\nvol. 66, no. 4, pp. 543\u2013578, 1996, doi: 10.2307/1170653.",
  "project_dir": "artifacts/projects/enhanced_cs.HC_2507.22671v1_Designing_for_Self_Regulation_in_Informal_Programm",
  "communication_dir": "artifacts/projects/enhanced_cs.HC_2507.22671v1_Designing_for_Self_Regulation_in_Informal_Programm/.agent_comm",
  "assigned_at": "2025-07-31T22:24:43.419914",
  "status": "assigned"
}